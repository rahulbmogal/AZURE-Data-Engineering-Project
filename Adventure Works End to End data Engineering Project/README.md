# Adventure Works Sales Analysis

![Alt text](https://github.com/rahulbmogal/Data-Engineering-projects/blob/main/Adventure%20Works%20End%20to%20End%20data%20Engineering%20Project/Adventure%20Works%20Sales%20Analysis.png?raw=true)



## On-prem DB to Azure Cloud Pipeline with Data Factory, Lake Storage, Spark, Databricks, Synapse, PowerBI

## Table of Contents

Project Overview
Key Insights

Project Architecture

1. Data Ingestion : Resource creation & Data Migration

2. Data Transformation

3.  Data Loading

4. Data Reporting

Credits

Contact

## Project Overview

This is an end-to-end data engineering project on the Azure cloud. Where I did data ingestion from an on-premise SQL Server to Azure Data Lake using Data Factory to transformation using Databricks and Spark, loading to Synapse, and reporting using PowerBI. Also, I used Azure Active Directory (AAD) and Azure Key Vault for data monitoring and governance purposes.

## Dataset
AdventureWorks is a database provided by Microsoft for free on online platforms. It is a product sample database originally published by Microsoft to demonstrate the supposed design of an SQL server database using SQL server.
- AdventureWorks database supports a manufacturing MNC named Adventure Works Cycles.
- It is a sample Online Transaction Processing (or OLTP) database, which is a type of data processing where multiple transactions occur concurrently. These are shipped by Microsoft with all of their SQL server products.

## Project Goals
- Establish a connection between on-premise SQL server and Azure cloud.
- Ingest tables into the Azure Data Lake.
- Apply data cleaning and transformation using Azure Databricks.
- Utilize Azure Synapse Analytics for loading clean data.
- Create interactive data visualizations and reports with Microsoft Power BI.
- Implement Azure Active Directory (AAD) and Azure Key Vault for monitoring and governance.

## Key Insights:

   Total Revenue: $ 708,300.00
   
   Total Sales: $ 713,600.00
   
   Touring Bikes is the top 1 category generating revenue with 32% followed by Road Bikes with 26% and Mountain Bikes with 24%.
   
   Total Number of customers are 847
   
   Revenue by Gender
    59% of the revenue is generated by Male customers and 41% of the revenue is generated by Female customers.
    This can be explained by males have more interest in doing outdoor activities with the different categories of 
    Bikes than females.

## Project Architecture
You can find the detailed information on the diagram below:

![Alt text](https://github.com/rahulbmogal/Data-Engineering-projects/blob/main/Adventure%20Works%20End%20to%20End%20data%20Engineering%20Project/Project%20pverview.png?raw=true)

## Data Ingestion
The data ingestion phase is the foundation for our analytics journey, bridging the gap between on-premise data sources and the Azure cloud by Microsoft Integration Runtime, I establish a secure and reliable connection between our on-premise SQL Server and Azure, enabling seamless data transfer to Azure Data Lake Storage Gen2. With Azure Data Factory orchestrating the ingestion process, I ensure efficient and scalable movement of th data.


![Alt text](https://github.com/rahulbmogal/Data-Engineering-projects/blob/main/Adventure%20Works%20End%20to%20End%20data%20Engineering%20Project/Screenshot%202024-04-27%20171932.png?raw=true)

## Resource Creation
In the initial phase of this project, I have created Azure data engineering pipeline by creating essential resources to facilitate seamless data ingestion, transformation, loading, and reporting.

1. Setup Resource Group
I begin with creating a dedicated resource group to house all the components of our data engineering solution. This resource group serves as a logical container for managing and organizing related Azure resources, providing a centralized hub for administration, monitoring, and access control.

2. Key Vault
Security is important and Azure Key Vault emerges as a critical component in safeguarding sensitive information such as credentials, secrets, and encryption keys. By creating an Azure Key Vault instance within our resource group, I establish a secure repository for storing and managing keys and secrets, ensuring data protection.

3. Storage Account
Next, I crated an Azure Storage Account to serve as the primary data repository for the data engineering pipeline. This storage account offers scalable, durable, and highly available cloud storage, enabling seamless ingestion, storage, and retrieval of data assets. With support for multiple data types and access tiers, Azure Storage empowers us to accommodate diverse data workloads while optimizing cost and performance.

4. Data Factory
Azure Data Factory emerges as the orchestrator of our data workflows, facilitating seamless data movement and transformation across hybrid and multicloud environments. By deploying an instance of Azure Data Factory within our resource group, we gain a powerful ETL (Extract, Transform, Load) service capable of orchestrating complex data integration pipelines, automating data workflows, and orchestrating data movement at scale.

5. Databricks
For advanced data processing and analytics, I have used Azure Databricks, a unified analytics platform built on Apache Spark. By provisioning an Azure Databricks workspace within our resource group, I done two stage transformation from Bronze to Silver and Silver to Gold as a clean data.
 
7. Synapse Analytics
I have used this resouce to load the cleaned data in to Azure SQL database through the pipeline and created the views for the tables present it it.

![Alt text](https://github.com/rahulbmogal/Data-Engineering-projects/blob/main/Adventure%20Works%20End%20to%20End%20data%20Engineering%20Project/Resouces-for-dataengineering-project.png?raw=true)



## Data Migration
In this phase of project, I  focus on seamlessly migrating data from our on-premises SQL Server environment to Azure Data Lake Storage.
Migrated the tables from on-premise SQL Server to Azure Data Lake Storage Gen2.

![Alt text](https://github.com/rahulbmogal/Data-Engineering-projects/blob/main/Adventure%20Works%20End%20to%20End%20data%20Engineering%20Project/Copy%20all%20Tables.png?raw=true)

![Alt text](https://github.com/rahulbmogal/Data-Engineering-projects/blob/main/Adventure%20Works%20End%20to%20End%20data%20Engineering%20Project/end%20to%20end%20pipeline%20run.png?raw=true)






## Data Transformation
Mounted Azure Blob Storage to Databricks to retrieve raw data from the Data Lake.
Used Spark Cluster in Azure Databricks to clean and refine the raw data.
Saved the cleaned data in a Delta format; optimized for further analysis.

![Alt text](https://github.com/rahulbmogal/Data-Engineering-projects/blob/main/Adventure%20Works%20End%20to%20End%20data%20Engineering%20Project/data%20Transformation.png?raw=true)


## Data Loading
In the data loading stage, I utilized Azure Synapse Analytics to efficiently load the cleaned data into an Azure SQL database through the pipeline. Additionally, I created views for the tables present in the database to facilitate easier data access and analysis. This involved setting up a SQL database and establishing a connection to the data lake, for seamless data transfer and management.

![Alt text](https://github.com/rahulbmogal/Data-Engineering-projects/blob/main/Adventure%20Works%20End%20to%20End%20data%20Engineering%20Project/Data%20Loading.png?raw=true)

## Data Reporting

In the final phase of Data visualization, I tried to include various charts to gain the valuable insights from the data. By connecting Microsoft Power BI to Azure Synapse, I used Azure SQL databases and create interactive and insightful data visualizations. From dynamic dashboards to detailed reports, Power BI enables stakeholders to explore data trends, uncover hidden patterns, and derive actionable insights to guide strategic decision-making.

Additionally, during this phase:

I created bar charts to analyze sales by project category.
I used pie charts to examine sales by gender.
I tried slicers to display the number of products.
I used cards to showcase total sales, revenue, total number of products, total number of customers, and the month & year.


![Alt text](https://github.com/rahulbmogal/Data-Engineering-projects/blob/main/Adventure%20Works%20End%20to%20End%20data%20Engineering%20Project/Adventure%20Works%20Sales%20Analysis.png?raw=true)


## Technologies Used:

   Data Source: SQL Server
   
   Orchestration: Azure Data Factory
   
   Ingestion: Azure Data Lake Gen2
   
   Storage: Azure Synapse Analytics
   
   Authentication and Secrets Management: Azure Active Directory and Azure Key Vault
   
   Data Visualization: PowerBI

## Credits

This Project is inspired by the video of the YouTube Channel "Mr. K Talks Tech"

## Contact Me

: www.linkedin.com/in/rahulmogal

: rahulmogal@outlook.com 
